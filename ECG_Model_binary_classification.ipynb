{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA7ha35YKPXi"
   },
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5272,
     "status": "ok",
     "timestamp": 1761312694168,
     "user": {
      "displayName": "D.M.S.H. DISSANAYAKE",
      "userId": "09664290018692185432"
     },
     "user_tz": -330
    },
    "id": "q4sbzpP7Kv_u"
   },
   "outputs": [],
   "source": [
    "import os, ast, json, random, numpy as np, pandas as pd, wfdb, tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, precision_recall_curve, f1_score\n",
    "tf.random.set_seed(42); np.random.seed(42); random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1761312698645,
     "user": {
      "displayName": "D.M.S.H. DISSANAYAKE",
      "userId": "09664290018692185432"
     },
     "user_tz": -330
    },
    "id": "dTGAsY-EL3wr"
   },
   "outputs": [],
   "source": [
    "PTBXL_ROOT = \"/Users/sahandissanayake/Downloads/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1\"\n",
    "ptbxl_csv = os.path.join(PTBXL_ROOT, \"ptbxl_database.csv\")\n",
    "scp_csv   = os.path.join(PTBXL_ROOT, \"scp_statements.csv\")\n",
    "assert os.path.exists(ptbxl_csv) and os.path.exists(scp_csv), \"Check PTB-XL paths.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1761312702586,
     "user": {
      "displayName": "D.M.S.H. DISSANAYAKE",
      "userId": "09664290018692185432"
     },
     "user_tz": -330
    },
    "id": "YxR0X6sdjdlH"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(ptbxl_csv)\n",
    "scp_df = pd.read_csv(scp_csv)\n",
    "\n",
    "# Normalize columns; ensure we have ['scp','diagnostic_class']\n",
    "scp_df = scp_df.copy()\n",
    "scp_df.columns = scp_df.columns.str.strip()\n",
    "if \"scp\" not in scp_df.columns:\n",
    "    if \"Unnamed: 0\" in scp_df.columns:\n",
    "        scp_df = scp_df.rename(columns={\"Unnamed: 0\": \"scp\"})\n",
    "    elif scp_df.index.name:\n",
    "        scp_df = scp_df.reset_index().rename(columns={scp_df.columns[0]: \"scp\"})\n",
    "    else:\n",
    "        # fallback: use first non-diagnostic_class column as scp\n",
    "        candidates = [c for c in scp_df.columns if c != \"diagnostic_class\"]\n",
    "        scp_df = scp_df.rename(columns={candidates[0]: \"scp\"})\n",
    "\n",
    "assert \"scp\" in scp_df.columns, f\"Missing 'scp' column: {scp_df.columns.tolist()}\"\n",
    "assert \"diagnostic_class\" in scp_df.columns, \"'diagnostic_class' column missing.\"\n",
    "\n",
    "# Build mapping: SCP code -> diagnostic_class (NORM/MI/STTC/HYP/CD)\n",
    "scp_df[\"scp\"] = scp_df[\"scp\"].astype(str).str.strip()\n",
    "scp_df[\"diagnostic_class\"] = scp_df[\"diagnostic_class\"].astype(str).str.strip()\n",
    "scp_to_class = dict(zip(scp_df[\"scp\"], scp_df[\"diagnostic_class\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1761312703422,
     "user": {
      "displayName": "D.M.S.H. DISSANAYAKE",
      "userId": "09664290018692185432"
     },
     "user_tz": -330
    },
    "id": "lD-K_pZKjaDQ",
    "outputId": "9e1ad00c-432e-4872-db8e-27567d25dc9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINARY CLASSIFICATION SETUP\n",
      "Classes â†’ ids: {'ABNORMAL': np.int64(0), 'NORMAL': np.int64(1)}\n",
      "Number of classes: 2\n",
      "\n",
      "ğŸ“Š Dataset Distribution:\n",
      "train : 17441 samples | {'NORMAL': 9179, 'ABNORMAL': 8262}\n",
      "val   :  2193 samples | {'NORMAL': 1193, 'ABNORMAL': 1000}\n",
      "test  :  2203 samples | {'NORMAL': 1179, 'ABNORMAL': 1024}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Binary mapping: NORM â†’ NORMAL, everything else â†’ ABNORMAL\n",
    "scp_to_class = {\n",
    "    \"NORM\": \"NORMAL\",     # Normal ECG\n",
    "    \"MI\": \"ABNORMAL\",     # Myocardial Infarction\n",
    "    \"STTC\": \"ABNORMAL\",   # ST/T changes\n",
    "    \"HYP\": \"ABNORMAL\",    # Hypertrophy\n",
    "    \"CD\": \"ABNORMAL\",     # Conduction Disturbance\n",
    "    \"SBRAD\": \"ABNORMAL\",\n",
    "    \"LAFB\": \"ABNORMAL\",\n",
    "    \"LBBB\": \"ABNORMAL\",\n",
    "    \"RBBB\": \"ABNORMAL\",\n",
    "    \"IRBBB\": \"ABNORMAL\",\n",
    "    \"CRBBB\": \"ABNORMAL\",\n",
    "    \"AVB\": \"ABNORMAL\",\n",
    "    \"PVC\": \"ABNORMAL\",\n",
    "    \"PAC\": \"ABNORMAL\",\n",
    "    \"LAE\": \"ABNORMAL\",\n",
    "    \"LVH\": \"ABNORMAL\",\n",
    "    \"RAE\": \"ABNORMAL\",\n",
    "    \"RVH\": \"ABNORMAL\",\n",
    "    \"ISC\": \"ABNORMAL\",\n",
    "    \"IMI\": \"ABNORMAL\",\n",
    "    \"ILMI\": \"ABNORMAL\",\n",
    "    \"ILAF\": \"ABNORMAL\",\n",
    "    \"ASMI\": \"ABNORMAL\",\n",
    "    \"INMI\": \"ABNORMAL\",\n",
    "    \"STACH\": \"ABNORMAL\",\n",
    "    \"NST\": \"ABNORMAL\",\n",
    "    \"TINV\": \"ABNORMAL\",\n",
    "    \"STDEP\": \"ABNORMAL\",\n",
    "    \"STEMI\": \"ABNORMAL\",\n",
    "    \"STD\": \"ABNORMAL\",\n",
    "    \"TNEG\": \"ABNORMAL\",\n",
    "    \"STEL\": \"ABNORMAL\",\n",
    "    \"SVT\": \"ABNORMAL\",\n",
    "    \"AFIB\": \"ABNORMAL\",\n",
    "    \"AFL\": \"ABNORMAL\",\n",
    "}\n",
    "\n",
    "def parse_scp_codes(s):\n",
    "    if isinstance(s, dict):\n",
    "        return s\n",
    "    if isinstance(s, str):\n",
    "        try:\n",
    "            return ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def majority_diag_class(scp_codes_dict):\n",
    "    \"\"\"Binary: if ANY abnormal code exists, return ABNORMAL\"\"\"\n",
    "    for scp, w in scp_codes_dict.items():\n",
    "        dc = scp_to_class.get(str(scp))\n",
    "        if dc == \"ABNORMAL\":\n",
    "            return \"ABNORMAL\"\n",
    "    return \"NORMAL\"\n",
    "\n",
    "# Check required columns\n",
    "required_cols = {\"scp_codes\", \"strat_fold\", \"filename_lr\"}\n",
    "assert required_cols.issubset(df.columns), f\"Missing columns: {required_cols - set(df.columns)}\"\n",
    "\n",
    "df = df.copy()\n",
    "df[\"scp_codes_dict\"] = df[\"scp_codes\"].apply(parse_scp_codes)\n",
    "df[\"y_class\"] = df[\"scp_codes_dict\"].apply(majority_diag_class)\n",
    "df = df.dropna(subset=[\"y_class\"]).reset_index(drop=True)\n",
    "\n",
    "# Encode to binary (0 or 1)\n",
    "le = LabelEncoder()\n",
    "le.fit(df[\"y_class\"])\n",
    "df[\"y_int\"] = le.transform(df[\"y_class\"]).astype(\"int32\")\n",
    "n_classes = len(le.classes_)  # Should be 2\n",
    "\n",
    "print(\"BINARY CLASSIFICATION SETUP\")\n",
    "print(f\"Classes â†’ ids: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "\n",
    "# Create path column\n",
    "df[\"record_path\"] = df[\"filename_lr\"]\n",
    "\n",
    "# Patient-wise split\n",
    "train_idx = df[\"strat_fold\"].isin(range(1, 9))\n",
    "val_idx   = df[\"strat_fold\"].eq(9)\n",
    "test_idx  = df[\"strat_fold\"].eq(10)\n",
    "\n",
    "df_train = df[train_idx].copy()\n",
    "df_val   = df[val_idx].copy()\n",
    "df_test  = df[test_idx].copy()\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset Distribution:\")\n",
    "for name, d in [(\"train\", df_train), (\"val\", df_val), (\"test\", df_test)]:\n",
    "    counts = d['y_class'].value_counts().to_dict()\n",
    "    print(f\"{name:6}: {len(d):5} samples | {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3567,
     "status": "ok",
     "timestamp": 1761312706991,
     "user": {
      "displayName": "D.M.S.H. DISSANAYAKE",
      "userId": "09664290018692185432"
     },
     "user_tz": -330
    },
    "id": "JPkLKqFcjk1Z",
    "outputId": "4f29d4da-329c-42a9-97e7-a06e18bfa23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary ECG Model Created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,720</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ conv1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_11       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> â”‚ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ conv1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_12       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> â”‚ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ conv1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> â”‚ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_5          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_13       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,400</span> â”‚ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_14       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,736</span> â”‚ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> â”‚ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_6          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_15       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,736</span> â”‚ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_16       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,736</span> â”‚ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_7          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_17       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">57,472</span> â”‚ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_18       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">114,816</span> â”‚ activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> â”‚ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_8          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ reshape_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_19       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">114,816</span> â”‚ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_20       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">114,816</span> â”‚ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> â”‚ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_9          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_21       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m12\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚      \u001b[38;5;34m2,720\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚        \u001b[38;5;34m128\u001b[0m â”‚ conv1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_11       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚      \u001b[38;5;34m7,200\u001b[0m â”‚ activation_11[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚        \u001b[38;5;34m128\u001b[0m â”‚ conv1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_12       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚      \u001b[38;5;34m7,200\u001b[0m â”‚ activation_12[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚        \u001b[38;5;34m128\u001b[0m â”‚ conv1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_12 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â”‚         \u001b[38;5;34m66\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_13 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚         \u001b[38;5;34m96\u001b[0m â”‚ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_5 (\u001b[38;5;33mReshape\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_5          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_5 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multiply_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ activation_11[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_13       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚     \u001b[38;5;34m14,400\u001b[0m â”‚ activation_13[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_14       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚     \u001b[38;5;34m28,736\u001b[0m â”‚ activation_14[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_14 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         â”‚        \u001b[38;5;34m260\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_15 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m320\u001b[0m â”‚ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_6 (\u001b[38;5;33mReshape\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚      \u001b[38;5;34m2,112\u001b[0m â”‚ activation_13[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_6          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_6 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multiply_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_15       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚     \u001b[38;5;34m28,736\u001b[0m â”‚ activation_15[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_16       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚     \u001b[38;5;34m28,736\u001b[0m â”‚ activation_16[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_16 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         â”‚        \u001b[38;5;34m260\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_17 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m320\u001b[0m â”‚ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_7 (\u001b[38;5;33mReshape\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_7          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_7 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multiply_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ activation_15[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_17       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚     \u001b[38;5;34m57,472\u001b[0m â”‚ activation_17[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_18       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚    \u001b[38;5;34m114,816\u001b[0m â”‚ activation_18[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_18 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚      \u001b[38;5;34m1,032\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_19 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚      \u001b[38;5;34m1,152\u001b[0m â”‚ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_8 (\u001b[38;5;33mReshape\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚      \u001b[38;5;34m8,320\u001b[0m â”‚ activation_17[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_8          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ reshape_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_8 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multiply_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_19       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚    \u001b[38;5;34m114,816\u001b[0m â”‚ activation_19[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_20       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚    \u001b[38;5;34m114,816\u001b[0m â”‚ activation_20[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_20 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚      \u001b[38;5;34m1,032\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_21 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚      \u001b[38;5;34m1,152\u001b[0m â”‚ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_9 (\u001b[38;5;33mReshape\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_9          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_9 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multiply_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ activation_19[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_21       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_21[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_22 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_23 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m65\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">548,315</span> (2.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m548,315\u001b[0m (2.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">546,203</span> (2.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m546,203\u001b[0m (2.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> (8.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,112\u001b[0m (8.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "INPUT_LEN, N_LEADS, BATCH = 1000, 12, 64\n",
    "\n",
    "def se_block(x, r=16):\n",
    "    c = x.shape[-1]\n",
    "    s = layers.GlobalAveragePooling1D()(x)\n",
    "    s = layers.Dense(max(1, c//r), activation=\"relu\")(s)\n",
    "    s = layers.Dense(c, activation=\"sigmoid\")(s)\n",
    "    return layers.Multiply()([x, layers.Reshape((1, c))(s)])\n",
    "\n",
    "def res_block(x, filters, kernel=7, stride=1):\n",
    "    shortcut = x\n",
    "    x = layers.Conv1D(filters, kernel, strides=stride, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Conv1D(filters, kernel, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x); x = se_block(x)\n",
    "    if shortcut.shape[-1] != filters or stride != 1:\n",
    "        shortcut = layers.Conv1D(filters, 1, strides=stride, padding=\"same\")(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    x = layers.Add()([x, shortcut]); x = layers.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def build_binary_ecg_model(input_len=1000, n_leads=12):\n",
    "    \"\"\"Binary classification: Normal vs Abnormal\"\"\"\n",
    "    inp = layers.Input(shape=(input_len, n_leads))\n",
    "    x = layers.Conv1D(32, 7, padding=\"same\")(inp)\n",
    "    x = layers.BatchNormalization()(x); x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = res_block(x, 32, 7, 1)\n",
    "    x = res_block(x, 64, 7, 2)\n",
    "    x = res_block(x, 64, 7, 1)\n",
    "    x = res_block(x, 128, 7, 2)\n",
    "    x = res_block(x, 128, 7, 1)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Binary output with sigmoid\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return Model(inp, out)\n",
    "\n",
    "model = build_binary_ecg_model(INPUT_LEN, N_LEADS)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(3e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Binary ECG Model Created\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59042,
     "status": "ok",
     "timestamp": 1761312766041,
     "user": {
      "displayName": "D.M.S.H. DISSANAYAKE",
      "userId": "09664290018692185432"
     },
     "user_tz": -330
    },
    "id": "SHkfLrG9kQYU",
    "outputId": "c384f2fa-1cf1-4b0a-9ec1-2601d826872c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary datasets created\n",
      "   Train batch: x=(64, 1000, 12), y=(64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 15:07:07.074780: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "def read_wfdb_record(rel_wo_ext, root=PTBXL_ROOT):\n",
    "    p = os.path.join(root, rel_wo_ext)\n",
    "    sig, _ = wfdb.rdsamp(p)\n",
    "    return sig.astype(np.float32)\n",
    "\n",
    "def augment_ecg_binary(sig, y_int):\n",
    "    \"\"\"Augmentation for binary classification\"\"\"\n",
    "    sig = sig.copy()\n",
    "    \n",
    "    # Check which class (0 or 1)\n",
    "    abnormal_label = le.transform([\"ABNORMAL\"])[0]\n",
    "    is_abnormal = (y_int == abnormal_label)\n",
    "    aug_prob = 0.7 if is_abnormal else 0.5\n",
    "    \n",
    "    # 1. Amplitude Scaling\n",
    "    if np.random.rand() < aug_prob:\n",
    "        scale = np.random.uniform(0.85, 1.15)\n",
    "        sig = sig * scale\n",
    "    \n",
    "    # 2. Gaussian Noise\n",
    "    if np.random.rand() < aug_prob:\n",
    "        noise = np.random.normal(0, 0.05, sig.shape)\n",
    "        sig = sig + noise\n",
    "    \n",
    "    # 3. Baseline Wander\n",
    "    if np.random.rand() < 0.5:\n",
    "        freq = np.random.uniform(0.2, 1.0)\n",
    "        t = np.linspace(0, 10, INPUT_LEN)\n",
    "        baseline = 0.1 * np.sin(2 * np.pi * freq * t)\n",
    "        sig = sig + baseline[:, None]\n",
    "    \n",
    "    # 4. Time shift\n",
    "    if np.random.rand() < 0.3:\n",
    "        shift = np.random.randint(-50, 50)\n",
    "        sig = np.roll(sig, shift, axis=0)\n",
    "    \n",
    "    return sig\n",
    "\n",
    "def _py_load_binary(path_bytes, y_int, augment=False):\n",
    "    path = path_bytes.numpy().decode(\"utf-8\")\n",
    "    sig = read_wfdb_record(path)\n",
    "    \n",
    "    # Pad/trim\n",
    "    if sig.shape != (INPUT_LEN, N_LEADS):\n",
    "        out = np.zeros((INPUT_LEN, N_LEADS), np.float32)\n",
    "        T = min(INPUT_LEN, sig.shape[0]); C = min(N_LEADS, sig.shape[1])\n",
    "        out[:T, :C] = sig[:T, :C]\n",
    "        sig = out\n",
    "    \n",
    "    # Augmentation\n",
    "    if augment:\n",
    "        sig = augment_ecg_binary(sig, y_int)\n",
    "    \n",
    "    # Z-score normalization\n",
    "    m = sig.mean(0, keepdims=True)\n",
    "    s = sig.std(0, keepdims=True) + 1e-6\n",
    "    sig = (sig - m) / s\n",
    "    \n",
    "    return sig.astype(np.float32), np.float32(y_int)\n",
    "\n",
    "def make_binary_ds(df_part, shuffle=False, augment=False):\n",
    "    paths = df_part[\"record_path\"].tolist()\n",
    "    ys = df_part[\"y_int\"].astype(\"float32\").tolist()\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, ys))\n",
    "    ds = ds.map(\n",
    "        lambda p, y: tf.py_function(\n",
    "            lambda p, y: _py_load_binary(p, y, augment=augment),\n",
    "            [p, y],\n",
    "            [tf.float32, tf.float32]\n",
    "        ),\n",
    "        num_parallel_calls=AUTO\n",
    "    )\n",
    "    ds = ds.map(\n",
    "        lambda x, y: (\n",
    "            tf.ensure_shape(x, [INPUT_LEN, N_LEADS]),\n",
    "            tf.ensure_shape(y, [])\n",
    "        ),\n",
    "        num_parallel_calls=AUTO\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(4096, reshuffle_each_iteration=True)\n",
    "    return ds.batch(BATCH).prefetch(AUTO)\n",
    "\n",
    "# Create datasets\n",
    "train_ds = make_binary_ds(df_train, shuffle=True, augment=True)\n",
    "val_ds = make_binary_ds(df_val, shuffle=False, augment=False)\n",
    "test_ds = make_binary_ds(df_test, shuffle=False, augment=False)\n",
    "\n",
    "print(\"Binary datasets created\")\n",
    "for xb, yb in train_ds.take(1):\n",
    "    print(f\"   Train batch: x={xb.shape}, y={yb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGFrbFUE0KMP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Class weights: {0: 1.0554950375211813, 1: 0.9500490249482515}\n",
      "   ABNORMAL: 1.06\n",
      "   NORMAL: 0.95\n",
      "ğŸš€ Starting binary classification training...\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 9.999999999999999e-05.\n",
      "Epoch 1/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.6432 - auc: 0.7066 - loss: 0.6306 - precision: 0.6952 - recall: 0.6132\n",
      "Epoch 1: val_auc improved from None to 0.83075, saving model to /Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 259ms/step - accuracy: 0.7140 - auc: 0.7849 - loss: 0.5587 - precision: 0.7278 - recall: 0.7294 - val_accuracy: 0.6156 - val_auc: 0.8308 - val_loss: 0.7729 - val_precision: 0.5865 - val_recall: 0.9941 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.00019999999999999998.\n",
      "Epoch 2/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.7711 - auc: 0.8468 - loss: 0.4817 - precision: 0.7754 - recall: 0.8152\n",
      "Epoch 2: val_auc improved from 0.83075 to 0.86884, saving model to /Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 279ms/step - accuracy: 0.7834 - auc: 0.8607 - loss: 0.4650 - precision: 0.7818 - recall: 0.8162 - val_accuracy: 0.7419 - val_auc: 0.8688 - val_loss: 0.6299 - val_precision: 0.6854 - val_recall: 0.9715 - learning_rate: 2.0000e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 3/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.8023 - auc: 0.8808 - loss: 0.4346 - precision: 0.8157 - recall: 0.8240\n",
      "Epoch 3: val_auc improved from 0.86884 to 0.88804, saving model to /Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 335ms/step - accuracy: 0.8056 - auc: 0.8857 - loss: 0.4260 - precision: 0.8092 - recall: 0.8251 - val_accuracy: 0.7770 - val_auc: 0.8880 - val_loss: 0.4943 - val_precision: 0.7234 - val_recall: 0.9556 - learning_rate: 3.0000e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 4/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.8236 - auc: 0.8997 - loss: 0.4007 - precision: 0.8340 - recall: 0.8459\n",
      "Epoch 4: val_auc improved from 0.88804 to 0.89688, saving model to /Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 343ms/step - accuracy: 0.8262 - auc: 0.9016 - loss: 0.3977 - precision: 0.8299 - recall: 0.8425 - val_accuracy: 0.8203 - val_auc: 0.8969 - val_loss: 0.4297 - val_precision: 0.7961 - val_recall: 0.9003 - learning_rate: 3.0000e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.00029898575366129145.\n",
      "Epoch 5/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.8300 - auc: 0.9090 - loss: 0.3824 - precision: 0.8460 - recall: 0.8461\n",
      "Epoch 5: val_auc improved from 0.89688 to 0.89858, saving model to /Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 331ms/step - accuracy: 0.8336 - auc: 0.9095 - loss: 0.3816 - precision: 0.8371 - recall: 0.8490 - val_accuracy: 0.8181 - val_auc: 0.8986 - val_loss: 0.4157 - val_precision: 0.7848 - val_recall: 0.9170 - learning_rate: 2.9899e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.00029595673058697357.\n",
      "Epoch 6/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.8338 - auc: 0.9128 - loss: 0.3751 - precision: 0.8503 - recall: 0.8479\n",
      "Epoch 6: val_auc improved from 0.89858 to 0.89867, saving model to /Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 335ms/step - accuracy: 0.8381 - auc: 0.9161 - loss: 0.3688 - precision: 0.8431 - recall: 0.8507 - val_accuracy: 0.7889 - val_auc: 0.8987 - val_loss: 0.4665 - val_precision: 0.8810 - val_recall: 0.7075 - learning_rate: 2.9596e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0002909538931178862.\n",
      "Epoch 7/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8362 - auc: 0.9150 - loss: 0.3723 - precision: 0.8529 - recall: 0.8478\n",
      "Epoch 7: val_auc did not improve from 0.89867\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 2s/step - accuracy: 0.8412 - auc: 0.9194 - loss: 0.3617 - precision: 0.8472 - recall: 0.8519 - val_accuracy: 0.8030 - val_auc: 0.8950 - val_loss: 0.4951 - val_precision: 0.8627 - val_recall: 0.7586 - learning_rate: 2.9095e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0002840448960485118.\n",
      "Epoch 8/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.8489 - auc: 0.9223 - loss: 0.3544 - precision: 0.8569 - recall: 0.8693\n",
      "Epoch 8: val_auc improved from 0.89867 to 0.90573, saving model to /Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 262ms/step - accuracy: 0.8498 - auc: 0.9243 - loss: 0.3507 - precision: 0.8531 - recall: 0.8634 - val_accuracy: 0.8272 - val_auc: 0.9057 - val_loss: 0.3903 - val_precision: 0.8126 - val_recall: 0.8868 - learning_rate: 2.8404e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00027532317171194046.\n",
      "Epoch 9/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741ms/step - accuracy: 0.8506 - auc: 0.9242 - loss: 0.3489 - precision: 0.8591 - recall: 0.8717\n",
      "Epoch 9: val_auc did not improve from 0.90573\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 752ms/step - accuracy: 0.8522 - auc: 0.9272 - loss: 0.3439 - precision: 0.8534 - recall: 0.8685 - val_accuracy: 0.8199 - val_auc: 0.8983 - val_loss: 0.4175 - val_precision: 0.8506 - val_recall: 0.8114 - learning_rate: 2.7532e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00026490666646784665.\n",
      "Epoch 10/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.8544 - auc: 0.9260 - loss: 0.3442 - precision: 0.8641 - recall: 0.8726\n",
      "Epoch 10: val_auc improved from 0.90573 to 0.90764, saving model to /Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 270ms/step - accuracy: 0.8575 - auc: 0.9307 - loss: 0.3355 - precision: 0.8595 - recall: 0.8718 - val_accuracy: 0.8130 - val_auc: 0.9076 - val_loss: 0.4648 - val_precision: 0.7633 - val_recall: 0.9514 - learning_rate: 2.6491e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00025293624568031.\n",
      "Epoch 11/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.8566 - auc: 0.9316 - loss: 0.3341 - precision: 0.8697 - recall: 0.8718\n",
      "Epoch 11: val_auc did not improve from 0.90764\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 285ms/step - accuracy: 0.8621 - auc: 0.9353 - loss: 0.3246 - precision: 0.8638 - recall: 0.8761 - val_accuracy: 0.8340 - val_auc: 0.9027 - val_loss: 0.4157 - val_precision: 0.8201 - val_recall: 0.8902 - learning_rate: 2.5294e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.00023957378875541792.\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 15:43:44.521940: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:453] ShuffleDatasetV3:22: Filling up shuffle buffer (this may take a while): 4053 of 4096\n",
      "2025-11-06 15:43:44.615495: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:483] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26s/step - accuracy: 0.8645 - auc: 0.9359 - loss: 0.3234 - precision: 0.8745 - recall: 0.8793 \n",
      "Epoch 12: val_auc improved from 0.90764 to 0.91024, saving model to /Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8779s\u001b[0m 30s/step - accuracy: 0.8666 - auc: 0.9390 - loss: 0.3147 - precision: 0.8667 - recall: 0.8821 - val_accuracy: 0.8345 - val_auc: 0.9102 - val_loss: 0.3942 - val_precision: 0.8347 - val_recall: 0.8676 - learning_rate: 2.3957e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.000225.\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:16:26.008662: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:453] ShuffleDatasetV3:22: Filling up shuffle buffer (this may take a while): 1256 of 4096\n",
      "2025-11-06 18:16:30.825691: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:483] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8625 - auc: 0.9380 - loss: 0.3186 - precision: 0.8762 - recall: 0.8735\n",
      "Epoch 13: val_auc did not improve from 0.91024\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1302s\u001b[0m 1s/step - accuracy: 0.8690 - auc: 0.9405 - loss: 0.3122 - precision: 0.8707 - recall: 0.8822 - val_accuracy: 0.8267 - val_auc: 0.9035 - val_loss: 0.4074 - val_precision: 0.8430 - val_recall: 0.8374 - learning_rate: 2.2500e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0002094119649058735.\n",
      "Epoch 14/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.8738 - auc: 0.9434 - loss: 0.3030 - precision: 0.8810 - recall: 0.8902\n",
      "Epoch 14: val_auc did not improve from 0.91024\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 257ms/step - accuracy: 0.8741 - auc: 0.9447 - loss: 0.2995 - precision: 0.8731 - recall: 0.8903 - val_accuracy: 0.7706 - val_auc: 0.8900 - val_loss: 0.6103 - val_precision: 0.8791 - val_recall: 0.6706 - learning_rate: 2.0941e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.00019302048490666353.\n",
      "Epoch 15/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8689 - auc: 0.9438 - loss: 0.3014 - precision: 0.8802 - recall: 0.8804\n",
      "Epoch 15: val_auc did not improve from 0.91024\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 2s/step - accuracy: 0.8743 - auc: 0.9466 - loss: 0.2949 - precision: 0.8769 - recall: 0.8854 - val_accuracy: 0.8326 - val_auc: 0.9058 - val_loss: 0.4523 - val_precision: 0.8177 - val_recall: 0.8910 - learning_rate: 1.9302e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.00017604722665003956.\n",
      "Epoch 16/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.8782 - auc: 0.9503 - loss: 0.2835 - precision: 0.8839 - recall: 0.8958\n",
      "Epoch 16: val_auc did not improve from 0.91024\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 257ms/step - accuracy: 0.8805 - auc: 0.9509 - loss: 0.2815 - precision: 0.8799 - recall: 0.8950 - val_accuracy: 0.8285 - val_auc: 0.9055 - val_loss: 0.4326 - val_precision: 0.7993 - val_recall: 0.9145 - learning_rate: 1.7605e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.00015872172433657134.\n",
      "Epoch 17/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8804 - auc: 0.9525 - loss: 0.2767 - precision: 0.8867 - recall: 0.8947\n",
      "Epoch 17: val_auc did not improve from 0.91024\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m973s\u001b[0m 4s/step - accuracy: 0.8828 - auc: 0.9544 - loss: 0.2719 - precision: 0.8822 - recall: 0.8970 - val_accuracy: 0.8167 - val_auc: 0.9016 - val_loss: 0.4588 - val_precision: 0.8573 - val_recall: 0.7955 - learning_rate: 1.5872e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00014127827566342863.\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:51:44.072341: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:453] ShuffleDatasetV3:22: Filling up shuffle buffer (this may take a while): 4069 of 4096\n",
      "2025-11-06 18:51:44.189832: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:483] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8872 - auc: 0.9540 - loss: 0.2713 - precision: 0.8921 - recall: 0.9026\n",
      "Epoch 18: val_auc did not improve from 0.91024\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 2s/step - accuracy: 0.8907 - auc: 0.9569 - loss: 0.2640 - precision: 0.8894 - recall: 0.9048 - val_accuracy: 0.8340 - val_auc: 0.9038 - val_loss: 0.4475 - val_precision: 0.8128 - val_recall: 0.9028 - learning_rate: 1.4128e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00012395277334996047.\n",
      "Epoch 19/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.8887 - auc: 0.9574 - loss: 0.2610 - precision: 0.8950 - recall: 0.9026\n",
      "Epoch 19: val_auc did not improve from 0.91024\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 257ms/step - accuracy: 0.8923 - auc: 0.9588 - loss: 0.2576 - precision: 0.8896 - recall: 0.9081 - val_accuracy: 0.8181 - val_auc: 0.9023 - val_loss: 0.4510 - val_precision: 0.7902 - val_recall: 0.9061 - learning_rate: 1.2395e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00010697951509333645.\n",
      "Epoch 20/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8930 - auc: 0.9608 - loss: 0.2511 - precision: 0.9019 - recall: 0.9039\n",
      "Epoch 20: val_auc did not improve from 0.91024\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 2s/step - accuracy: 0.8967 - auc: 0.9627 - loss: 0.2455 - precision: 0.8950 - recall: 0.9104 - val_accuracy: 0.8190 - val_auc: 0.8974 - val_loss: 0.6251 - val_precision: 0.7779 - val_recall: 0.9338 - learning_rate: 1.0698e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 9.058803509412646e-05.\n",
      "Epoch 21/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9022 - auc: 0.9662 - loss: 0.2355 - precision: 0.9082 - recall: 0.9143\n",
      "Epoch 21: val_auc did not improve from 0.91024\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 259ms/step - accuracy: 0.9024 - auc: 0.9662 - loss: 0.2337 - precision: 0.8997 - recall: 0.9168 - val_accuracy: 0.8299 - val_auc: 0.8996 - val_loss: 0.4867 - val_precision: 0.8183 - val_recall: 0.8835 - learning_rate: 9.0588e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 7.500000000000002e-05.\n",
      "Epoch 22/30\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9043 - auc: 0.9660 - loss: 0.2345 - precision: 0.9115 - recall: 0.9152\n",
      "Epoch 22: val_auc did not improve from 0.91024\n",
      "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 266ms/step - accuracy: 0.9060 - auc: 0.9679 - loss: 0.2273 - precision: 0.9044 - recall: 0.9185 - val_accuracy: 0.8171 - val_auc: 0.8976 - val_loss: 0.6274 - val_precision: 0.7812 - val_recall: 0.9220 - learning_rate: 7.5000e-05\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Binary class weights\n",
    "classes = np.array([0, 1])\n",
    "cw = compute_class_weight(\n",
    "    class_weight=\"balanced\", \n",
    "    classes=classes, \n",
    "    y=df_train[\"y_int\"].values\n",
    ")\n",
    "class_weight = {int(k): float(v) for k, v in zip(classes, cw)}\n",
    "print(f\"ğŸ“Š Class weights: {class_weight}\")\n",
    "print(f\"   {le.classes_[0]}: {class_weight[0]:.2f}\")\n",
    "print(f\"   {le.classes_[1]}: {class_weight[1]:.2f}\")\n",
    "\n",
    "# Checkpoint path\n",
    "ckpt_path = \"/Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\"\n",
    "os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
    "\n",
    "# Learning rate schedule\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < 3:\n",
    "        return 3e-4 * (epoch + 1) / 3\n",
    "    else:\n",
    "        return 3e-4 * 0.5 * (1 + np.cos(np.pi * (epoch - 3) / 27))\n",
    "\n",
    "# Callbacks\n",
    "cbs = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        ckpt_path,\n",
    "        monitor=\"val_auc\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_auc\",\n",
    "        mode=\"max\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"ğŸš€ Starting binary classification training...\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=cbs,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BjgRuna6BSxM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary model loaded!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model(\n",
    "    \"/Users/sahandissanayake/Documents/PythonLib 3.11/models/best_ptbxl_binary.keras\"\n",
    ")\n",
    "print(\"Binary model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "acjeKZ7_j3Oc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BINARY MODEL EVALUATION\n",
      "============================================================\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.8320 - auc: 0.9025 - loss: 0.4139 - precision: 0.8270 - recall: 0.8677\n",
      "\n",
      "Test Accuracy:  0.8320 (83.20%)\n",
      "Test Precision: 0.8270\n",
      "Test Recall:    0.8677\n",
      "Test AUC:       0.9025\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    ABNORMAL     0.8385    0.7910    0.8141      1024\n",
      "      NORMAL     0.8270    0.8677    0.8469      1179\n",
      "\n",
      "    accuracy                         0.8320      2203\n",
      "   macro avg     0.8328    0.8294    0.8305      2203\n",
      "weighted avg     0.8324    0.8320    0.8316      2203\n",
      "\n",
      "\n",
      "============================================================\n",
      "CONFUSION MATRIX\n",
      "============================================================\n",
      "[[ 810  214]\n",
      " [ 156 1023]]\n",
      "\n",
      "ABNORMAL   | TN= 810 | FP= 214\n",
      "NORMAL     | FN= 156 | TP=1023\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Recreate test dataset\n",
    "test_ds = make_binary_ds(df_test, shuffle=False, augment=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BINARY MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = model.evaluate(test_ds, return_dict=True)\n",
    "print(f\"\\nTest Accuracy:  {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)\")\n",
    "print(f\"Test Precision: {results['precision']:.4f}\")\n",
    "print(f\"Test Recall:    {results['recall']:.4f}\")\n",
    "print(f\"Test AUC:       {results['auc']:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_true = df_test[\"y_int\"].values\n",
    "y_pred_prob = model.predict(test_ds, verbose=0).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*60)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "print(f\"\\n{le.classes_[0]:10} | TN={cm[0,0]:4} | FP={cm[0,1]:4}\")\n",
    "print(f\"{le.classes_[1]:10} | FN={cm[1,0]:4} | TP={cm[1,1]:4}\")\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "auc_score = roc_auc_score(y_true, y_pred_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC={auc_score:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Binary ECG Classification')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8cvrUJJXj6Wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example predictions:\n",
      "\n",
      "âœ… Record 0: True=NORMAL\n",
      "   {'prediction': 'NORMAL', 'confidence': 0.998207688331604, 'ABNORMAL_probability': 0.001792311668395996, 'NORMAL_probability': 0.998207688331604}\n",
      "\n",
      "âœ… Record 1: True=NORMAL\n",
      "   {'prediction': 'NORMAL', 'confidence': 0.5420249104499817, 'ABNORMAL_probability': 0.4579750895500183, 'NORMAL_probability': 0.5420249104499817}\n",
      "\n",
      "âœ… Record 27: True=ABNORMAL\n",
      "   {'prediction': 'ABNORMAL', 'confidence': 0.5073937177658081, 'ABNORMAL_probability': 0.5073937177658081, 'NORMAL_probability': 0.4926062524318695}\n",
      "\n",
      "âœ… Record 34: True=ABNORMAL\n",
      "   {'prediction': 'ABNORMAL', 'confidence': 0.6781120300292969, 'ABNORMAL_probability': 0.6781120300292969, 'NORMAL_probability': 0.32188794016838074}\n"
     ]
    }
   ],
   "source": [
    "def predict_binary_diagnosis(rel_wo_ext):\n",
    "    \"\"\"Predict Normal vs Abnormal\"\"\"\n",
    "    sig = read_wfdb_record(rel_wo_ext)\n",
    "    \n",
    "    # Preprocess\n",
    "    if sig.shape != (INPUT_LEN, N_LEADS):\n",
    "        out = np.zeros((INPUT_LEN, N_LEADS), np.float32)\n",
    "        T = min(INPUT_LEN, sig.shape[0]); C = min(N_LEADS, sig.shape[1])\n",
    "        out[:T, :C] = sig[:T, :C]\n",
    "        sig = out\n",
    "    \n",
    "    m, s = sig.mean(0, keepdims=True), sig.std(0, keepdims=True) + 1e-6\n",
    "    sig = (sig - m) / s\n",
    "    \n",
    "    # Predict\n",
    "    prob = model.predict(sig[None, ...], verbose=0)[0][0]\n",
    "    pred_class = le.classes_[1] if prob > 0.5 else le.classes_[0]\n",
    "    \n",
    "    return {\n",
    "        \"prediction\": pred_class,\n",
    "        \"confidence\": float(max(prob, 1-prob)),\n",
    "        f\"{le.classes_[0]}_probability\": float(1 - prob),\n",
    "        f\"{le.classes_[1]}_probability\": float(prob)\n",
    "    }\n",
    "\n",
    "# Test predictions\n",
    "print(\"Example predictions:\")\n",
    "for i in [0, 1, 27, 34]:\n",
    "    result = predict_binary_diagnosis(df_test.iloc[i][\"record_path\"])\n",
    "    true_class = le.classes_[df_test.iloc[i][\"y_int\"]]\n",
    "    match = \"âœ…\" if result[\"prediction\"] == true_class else \"âŒ\"\n",
    "    print(f\"\\n{match} Record {i}: True={true_class}\")\n",
    "    print(f\"   {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7dUG-mpSmAU6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the first record in the test set:\n",
      "{'prediction': 'ABNORMAL', 'confidence': 0.5073937177658081, 'ABNORMAL_probability': 0.5073937177658081, 'NORMAL_probability': 0.4926062524318695}\n",
      "\n",
      "Prediction for the second record in the test set:\n",
      "{'prediction': 'ABNORMAL', 'confidence': 0.6781120300292969, 'ABNORMAL_probability': 0.6781120300292969, 'NORMAL_probability': 0.32188794016838074}\n"
     ]
    }
   ],
   "source": [
    "# Example predictions using the binary function\n",
    "print(\"Prediction for the first record in the test set:\")\n",
    "result1 = predict_binary_diagnosis(df_test.iloc[27][\"record_path\"])\n",
    "print(result1)\n",
    "\n",
    "print(\"\\nPrediction for the second record in the test set:\")\n",
    "result2 = predict_binary_diagnosis(df_test.iloc[34][\"record_path\"])\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7Jjbg9VKscpC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with PTB-XL record:\n",
      "{'prediction': 'NORMAL', 'confidence': 0.998207688331604, 'ABNORMAL_probability': 0.001792311668395996, 'NORMAL_probability': 0.998207688331604}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_ecg_file(file_path):\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    if ext in ['.dat', '.hea', '']:  # WFDB (assumes .dat/.hea, no extension)\n",
    "        sig, _ = wfdb.rdsamp(file_path)\n",
    "        return sig\n",
    "    elif ext == '.csv':\n",
    "        df = pd.read_csv(file_path)\n",
    "        sig = df.select_dtypes(include=[np.number]).values\n",
    "        return sig\n",
    "    elif ext == '.npy':\n",
    "        sig = np.load(file_path)\n",
    "        return sig\n",
    "    elif ext == '.mat':\n",
    "        mat = scipy.io.loadmat(file_path)\n",
    "        for key in ['ecg', 'signal', 'val', 'data']:\n",
    "            if key in mat:\n",
    "                return np.array(mat[key])\n",
    "        raise ValueError(\"MAT file: No ECG signal found in keys.\")\n",
    "    elif ext == '.json':\n",
    "        with open(file_path, 'r') as f:\n",
    "            jdata = json.load(f)\n",
    "        # Try common keys for ECG data\n",
    "        for key in ['ecg', 'signal', 'val', 'data']:\n",
    "            if key in jdata:\n",
    "                sig = np.array(jdata[key])\n",
    "                if sig.ndim == 1:  # Single lead or flat, make shape (T, 1)\n",
    "                    sig = sig.reshape(-1, 1)\n",
    "                return sig\n",
    "        # If top-level is a list (not dict), treat as signal array\n",
    "        if isinstance(jdata, list):\n",
    "            sig = np.array(jdata)\n",
    "            if sig.ndim == 1:\n",
    "                sig = sig.reshape(-1, 1)\n",
    "            return sig\n",
    "        raise ValueError(\"JSON file: No ECG signal found in keys or top-level list.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_path}\")\n",
    "\n",
    "def preprocess_ecg(sig, input_len=1000, n_leads=12):\n",
    "    sig = np.asarray(sig, dtype=np.float32)\n",
    "    out = np.zeros((input_len, n_leads), np.float32)\n",
    "    T = min(input_len, sig.shape[0])\n",
    "    C = min(n_leads, sig.shape[1])\n",
    "    out[:T, :C] = sig[:T, :C]\n",
    "    m = out.mean(0, keepdims=True)\n",
    "    s = out.std(0, keepdims=True) + 1e-6\n",
    "    out = (out - m) / s\n",
    "    return out\n",
    "\n",
    "def predict_cvd(file_path, model, label_encoder, input_len=1000, n_leads=12):\n",
    "    \"\"\"Predict binary (Normal/Abnormal) from external ECG file\"\"\"\n",
    "    sig = load_ecg_file(file_path)\n",
    "    sig = preprocess_ecg(sig, input_len=input_len, n_leads=n_leads)\n",
    "    \n",
    "    # Binary prediction\n",
    "    prob = model.predict(sig[None, ...], verbose=0)[0][0]\n",
    "    pred_class = label_encoder.classes_[1] if prob > 0.5 else label_encoder.classes_[0]\n",
    "    \n",
    "    return {\n",
    "        'pred_class': pred_class,\n",
    "        'confidence': float(max(prob, 1-prob)),\n",
    "        'probs': {\n",
    "            label_encoder.classes_[0]: float(1 - prob),\n",
    "            label_encoder.classes_[1]: float(prob)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test with an actual PTB-XL record (already preprocessed by the model)\n",
    "# This uses the existing predict_diagnosis_from_wfdb function instead\n",
    "test_record_path = df_test.iloc[0][\"record_path\"]\n",
    "print(\"Testing with PTB-XL record:\")\n",
    "print(predict_binary_diagnosis(test_record_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hNkwW1FDvEvn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found. Please update the path.\n",
      "Using PTB-XL test example instead:\n",
      "{'prediction': 'NORMAL', 'confidence': 0.998207688331604, 'ABNORMAL_probability': 0.001792311668395996, 'NORMAL_probability': 0.998207688331604}\n"
     ]
    }
   ],
   "source": [
    "# Example: Predict from external file\n",
    "my_file = \"/Users/sahandissanayake/Documents/my_ecg_file.mat\"  # or .csv, .npy, .json\n",
    "\n",
    "if os.path.exists(my_file):\n",
    "    prediction = predict_cvd(my_file, model, le)\n",
    "    print(prediction)\n",
    "else:\n",
    "    print(f\"File not found. Please update the path.\")\n",
    "    print(\"Using PTB-XL test example instead:\")\n",
    "    print(predict_binary_diagnosis(df_test.iloc[0][\"record_path\"]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
